# Custom Tokenizer (GenAI with JavaScript 1.0)

A simple JavaScript-based tokenizer for text processing â€” supports vocabulary generation, encoding, decoding, and special tokens.  
This project demonstrates the basics of how tokenizers work in NLP and GenAI models.

---

# Features
- Generate vocabulary from a text corpus.
- Encode text into token IDs.
- Decode token IDs back into text.
- Supports **special tokens**:
  - `<PAD>` â€” Padding
  - `<UNK>` â€” Unknown token
  - `<BOS>` â€” Beginning of sentence
  - `<EOS>` â€” End of sentence

---

# File Structure
custom-tokenizer/
â”‚
â”œâ”€â”€ corpus.txt # Input text corpus
â”œâ”€â”€ vocab.json # Generated vocabulary file
â”œâ”€â”€ tokenizer.js # Tokenizer class
â”œâ”€â”€ demo.js # Example usage script
â””â”€â”€ README.md # Project documentation



## âš™ï¸ Setup

### 1ï¸âƒ£ Install Node.js
Download & install from [https://nodejs.org](https://nodejs.org).

### 2ï¸âƒ£ Clone the Repository

(https://github.com/yash12994/custom-tokenizer.git)
cd custom-tokenizer

3ï¸âƒ£ Initialize Project
npm init -y
ğŸ’» Usage
1. Build Vocabulary
From corpus.txt, run:
node demo.js
This generates vocab.json with tokens mapped to IDs.

2. Encode Text
javascript
const Tokenizer = require('./tokenizer');
const tokenizer = new Tokenizer('vocab.json');

console.log(tokenizer.encode("Hello world"));

3. Decode Tokens
javascript
console.log(tokenizer.decode([4, 5]));

ğŸ“Œ Example
corpus.txt
Hello world
This is a tokenizer demo

Generated vocab.json
{
  "<PAD>": 0,
  "<UNK>": 1,
  "<BOS>": 2,
  "<EOS>": 3,
  "Hello": 4,
  "world": 5,
  "This": 6,
  "is": 7,
  "a": 8,
  "tokenizer": 9,
  "demo": 10
}




